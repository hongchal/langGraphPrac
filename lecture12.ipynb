{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "small_llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_community import GmailToolkit\n",
    "\n",
    "from langchain_google_community.gmail.utils import (\n",
    "    build_resource_service,\n",
    "    get_gmail_credentials,\n",
    ")\n",
    "\n",
    "# Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "# For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "credentials = get_gmail_credentials(\n",
    "    token_file=\"./google/gmail_token.json\",\n",
    "    scopes=[\"https://mail.google.com/\"],\n",
    "    client_secrets_file=\"./google/gmail_credentials.json\",\n",
    ")\n",
    "api_resource = build_resource_service(credentials=credentials)\n",
    "gmail_toolkit = GmailToolkit(api_resource=api_resource)\n",
    "gmail_tool_list = gmail_toolkit.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "loaded_tool_list = load_tools(\n",
    "    [\"arxiv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma \n",
    "from langchain_openai import OpenAIEmbeddings  \n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name = 'real_estate_tax',\n",
    "    persist_directory='./real_estate_tax_collection'\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name='real_estate_tax_retriever',\n",
    "    description='Contains information about real estate tax up to December 2024',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply, search_tool, retriever_tool] + gmail_tool_list + loaded_tool_list\n",
    "llm_with_tools = small_llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    # 메시지와 요약을 state에서 가져옵니다.\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    \n",
    "    # 요약이 비어있지 않으면, 요약을 메시지 앞에 추가합니다.\n",
    "    if summary != '':\n",
    "        messages = [SystemMessage(content=f'Here is the summary of the earlier conversation: {summary}')] + messages\n",
    "    \n",
    "    # LLM과 도구를 사용하여 메시지에 대한 응답을 생성합니다.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 응답 메시지를 포함하는 새로운 state를 반환합니다.\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state: AgentState) -> AgentState: \n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "\n",
    "    summary_prompt = f'summarize this chat history below:\\n\\nchat history:{messages}'\n",
    "\n",
    "    if summary != '':\n",
    "        summary_prompt = f'''summarize this chat history below while looking at the summary of earlier conversations\n",
    "chat_history:{messages}\n",
    "summary:{summary}'''\n",
    "        \n",
    "    summary = small_llm.invoke(summary_prompt)\n",
    "\n",
    "    return {'summary': summary.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete_messages(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    주어진 state에서 오래된 메시지를 삭제합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 메시지를 포함하는 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 삭제된 메시지를 포함하는 새로운 state.\n",
    "    \"\"\"\n",
    "    # state에서 메시지를 가져옵니다.\n",
    "    messages = state['messages']\n",
    "    # 마지막 세 개의 메시지를 제외한 나머지 메시지를 삭제합니다.\n",
    "    delete_messages = [RemoveMessage(id=message.id) for message in messages[:-3]]\n",
    "    # 삭제된 메시지를 포함하는 새로운 state를 반환합니다.\n",
    "    return {'messages': delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal \n",
    "\n",
    "def should_continue(state: AgentState) -> Literal['tools', 'summarize_messgaes']:\n",
    "    messages = state['messages']\n",
    "    last_ai_message = messages[-1]\n",
    "\n",
    "    if last_ai_message.tool_calls:\n",
    "        return 'tools'\n",
    "    \n",
    "    return 'summarize_messages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15af7f4d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_node(delete_messages)\n",
    "graph_builder.add_node(summarize_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15af7f4d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END \n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', 'summarize_messages']\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "graph_builder.add_edge('summarize_messages', 'delete_messages')\n",
    "graph_builder.add_edge('delete_messages', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph= graph_builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "robert@hanpoom.com으로 Attention Is All You Need 논문을 요약해서 이메일 초안을 작성해주세요\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_gIgm366s5qp7wVQGPIYBPq0y)\n",
      " Call ID: call_gIgm366s5qp7wVQGPIYBPq0y\n",
      "  Args:\n",
      "    query: Attention Is All You Need\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2024-07-22\n",
      "Title: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\n",
      "Authors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\n",
      "Summary: The inference demand for LLMs has skyrocketed in recent months, and serving\n",
      "models with low latencies remains challenging due to the quadratic input length\n",
      "complexity of the attention layers. In this work, we investigate the effect of\n",
      "dropping MLP and attention layers at inference time on the performance of\n",
      "Llama-v2 models. We find that dropping dreeper attention layers only marginally\n",
      "decreases performance but leads to the best speedups alongside dropping entire\n",
      "layers. For example, removing 33\\% of attention layers in a 13B Llama2 model\n",
      "results in a 1.8\\% drop in average performance over the OpenLLM benchmark. We\n",
      "also observe that skipping layers except the latter layers reduces performances\n",
      "for more layers skipped, except for skipping the attention layers.\n",
      "\n",
      "Published: 2021-07-16\n",
      "Title: All the attention you need: Global-local, spatial-channel attention for image retrieval\n",
      "Authors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\n",
      "Summary: We address representation learning for large-scale instance-level image\n",
      "retrieval. Apart from backbone, training pipelines and loss functions, popular\n",
      "approaches have focused on different spatial pooling and attention mechanisms,\n",
      "which are at the core of learning a powerful global image representation. There\n",
      "are different forms of attention according to the interaction of elements of\n",
      "the feature tensor (local and global) and the dimensions where it is applied\n",
      "(spatial and channel). Unfortunately, each study addresses only one or two\n",
      "forms of attention and applies it to different problems like classification,\n",
      "detection or retrieval.\n",
      "  We present global-local attention module (GLAM), which is attached at the end\n",
      "of a backbone network and incorporates all four forms of attention: local and\n",
      "global, spatial and channel. We obtain a new feature tensor and, by spatial\n",
      "pooling, we learn a powerful embedding for image retrieval. Focusing on global\n",
      "descriptors, we provide empirical evidence of the interaction of all forms of\n",
      "attention and improve the state of the art on standard benchmarks.\n",
      "\n",
      "Published: 2023-06-02\n",
      "Title: RITA: Group Attention is All You Need for Timeseries Analytics\n",
      "Authors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li\n",
      "Summary: Timeseries analytics is of great importance in many real-world applications.\n",
      "Recently, the Transformer model, popular in natural language processing, has\n",
      "been leveraged to learn high quality feature embeddings from timeseries, core\n",
      "to the performance of various timeseries analytics tasks. However, the\n",
      "quadratic time and space complexities limit Transformers' scalability,\n",
      "especially for long timeseries. To address these issues, we develop a\n",
      "timeseries analytics tool, RITA, which uses a novel attention mechanism, named\n",
      "group attention, to address this scalability issue. Group attention dynamically\n",
      "clusters the objects based on their similarity into a small number of groups\n",
      "and approximately computes the attention at the coarse group granularity. It\n",
      "thus significantly reduces the time and space complexity, yet provides a\n",
      "theoretical guarantee on the quality of the computed attention. The dynamic\n",
      "scheduler of RITA continuously adapts the number of groups and the batch size\n",
      "in the training process, ensuring group attention always uses the fewest groups\n",
      "needed to meet the approximation quality requirement. Extensive experiments on\n",
      "various timeseries datasets and analytics tasks demonstrate that RITA\n",
      "outperforms the state-of-the-art in accuracy and is significantly faster --\n",
      "with speedups of up to 63X.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  create_gmail_draft (call_LOSMdf5W8qEyKYktegvaAhn1)\n",
      " Call ID: call_LOSMdf5W8qEyKYktegvaAhn1\n",
      "  Args:\n",
      "    message: 안녕하세요,\n",
      "\n",
      "\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "    to: ['robert@hanpoom.com']\n",
      "    subject: Attention Is All You Need 논문 요약\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: create_gmail_draft\n",
      "\n",
      "Draft created. Draft Id: r8199476668056932988\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일 초안이 작성되었습니다. 내용은 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "안녕하세요,\n",
      "\n",
      "\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "이메일을 발송하시려면 확인 후 진행해 주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일 초안이 작성되었습니다. 내용은 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "안녕하세요,\n",
      "\n",
      "\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "이메일을 발송하시려면 확인 후 진행해 주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일 초안이 작성되었습니다. 내용은 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "안녕하세요,\n",
      "\n",
      "\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "이메일을 발송하시려면 확인 후 진행해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'summarize_paper'\n",
    "    }\n",
    "}\n",
    "\n",
    "query = 'robert@hanpoom.com으로 Attention Is All You Need 논문을 요약해서 이메일 초안을 작성해주세요'\n",
    "for chunk in graph.stream({'messages': [HumanMessage(query)], 'summary': ''}, config=config, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LOSMdf5W8qEyKYktegvaAhn1', 'function': {'arguments': '{\"message\":\"안녕하세요,\\\\n\\\\n\\\\\"Attention Is All You Need\\\\\" 논문에 대한 요약을 공유하고자 합니다.\\\\n\\\\n이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\\\\n\\\\n이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\\\\n\\\\n감사합니다.\",\"to\":[\"robert@hanpoom.com\"],\"subject\":\"Attention Is All You Need 논문 요약\"}', 'name': 'create_gmail_draft'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 1572, 'total_tokens': 1883, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1536}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a4f04d8f-01f2-407a-b997-23c0ac5f9fec-0', tool_calls=[{'name': 'create_gmail_draft', 'args': {'message': '안녕하세요,\\n\\n\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\\n\\n이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\\n\\n이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\\n\\n감사합니다.', 'to': ['robert@hanpoom.com'], 'subject': 'Attention Is All You Need 논문 요약'}, 'id': 'call_LOSMdf5W8qEyKYktegvaAhn1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1572, 'output_tokens': 311, 'total_tokens': 1883, 'input_token_details': {'audio': 0, 'cache_read': 1536}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Draft created. Draft Id: r8199476668056932988', name='create_gmail_draft', id='c6e6ecb3-8be4-41f5-a377-717d49211c3b', tool_call_id='call_LOSMdf5W8qEyKYktegvaAhn1'),\n",
       " AIMessage(content='이메일 초안이 작성되었습니다. 내용은 다음과 같습니다:\\n\\n---\\n\\n안녕하세요,\\n\\n\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\\n\\n이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\\n\\n이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\\n\\n감사합니다.\\n\\n---\\n\\n이메일을 발송하시려면 확인 후 진행해 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 1908, 'total_tokens': 2204, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1792}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'finish_reason': 'stop', 'logprobs': None}, id='run-f2d19d3c-b532-473e-855e-9e3d0b84e2ce-0', usage_metadata={'input_tokens': 1908, 'output_tokens': 296, 'total_tokens': 2204, 'input_token_details': {'audio': 0, 'cache_read': 1792}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_message_list = graph.get_state(config).values['messages']\n",
    "current_message_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the chat, a user requested a summary of the paper \"Attention Is All You Need\" to be drafted into an email addressed to Robert. The AI began by querying the relevant information regarding the paper and later summarized its findings. The summary highlighted the increasing demand for inference in large language models (LLMs) and the challenges related to low-latency model serving. It discussed an investigation into the effects of removing MLP and attention layers during inference on Llama-v2 model performance, revealing that dropping certain layers only slightly decreased performance while improving speed.\\n\\nThe AI created a draft email summarizing these points in Korean, inviting further questions or discussions. The email was prepared for sending, and the user was prompted to review it before dispatching.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "이메일을 전송해주세요\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  send_gmail_message (call_rq6sPoExTSv8hoFHCIpZj5rh)\n",
      " Call ID: call_rq6sPoExTSv8hoFHCIpZj5rh\n",
      "  Args:\n",
      "    message: 안녕하세요,\n",
      "\n",
      "\"Attention Is All You Need\" 논문에 대한 요약을 공유하고자 합니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델(LLM)의 추론 수요가 최근 몇 달간 급증하고 있으며, 낮은 대기 시간으로 모델을 제공하는 것이 어려움을 겪고 있음을 강조합니다. 연구에서는 추론 시 MLP 및 주의(attention) 레이어를 제거하는 것이 Llama-v2 모델의 성능에 미치는 영향을 조사하였습니다. 주요 발견으로는, 깊은 주의 레이어를 제거하는 것이 성능을 소폭 감소시키지만 속도 향상에 기여한다는 것입니다. 예를 들어, 13B Llama2 모델에서 33%의 주의 레이어를 제거하면 OpenLLM 벤치마크에서 평균 성능이 1.8% 감소하는 것으로 나타났습니다. 또한, 마지막 레이어를 제외한 레이어를 건너뛰는 것이 성능을 저하시킨다는 점도 관찰되었습니다.\n",
      "\n",
      "이 논문은 대규모 언어 모델의 성능과 효율성을 개선하기 위한 중요한 통찰을 제공합니다. 추가적인 질문이나 논의가 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "감사합니다.\n",
      "    to: ['robert@hanpoom.com']\n",
      "    subject: Attention Is All You Need 논문 요약\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: send_gmail_message\n",
      "\n",
      "Message sent. Message Id: 196ec1e128e9b3c4\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일이 성공적으로 전송되었습니다. 추가적으로 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일이 성공적으로 전송되었습니다. 추가적으로 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이메일이 성공적으로 전송되었습니다. 추가적으로 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "send_query = '이메일을 전송해주세요'\n",
    "for chunk in graph.stream({'messages': [HumanMessage(send_query)]}, config=config, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
